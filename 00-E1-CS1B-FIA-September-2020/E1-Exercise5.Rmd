---
title: "Statistics with R"
subtitle: "Introduction to R for Actuarial Students"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
---

* Introduction to R for Actuarial Students

* CS1B Curriculum

* Introduction to R programming
* Fundamentals of Statistical Analysis

* Question 2 - Chi Square Test

---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
```

```{css, echo=FALSE}
pre {
  background: #ADD8E6;
  max-width: 100%;
  overflow-x: scroll;
}
```

5 A waiting time random variable X follows an Exponential distribution with rate l
parameterised as f (x) = le–lx (x > 0, l > 0).
The rate l has a Gamma prior distribution with parameters $a$ and $s$. 

* A Bayesian credibility model provides that the posterior mean of 1/l can be expressed as
Z3x + (1– Z)3
s
α – 1
, where Z = n
α + n – 1
with n being the number of past waiting times observed.

* Assume that the parameters of the prior Gamma distribution are $a = 5$ and $s = 1$.

---

Sure! This exercise involves working with a Bayesian credibility model and using Monte Carlo simulations to estimate certain parameters. Here's a breakdown of the steps and code provided:

### Background
You are dealing with a waiting time random variable \( X \) that follows an Exponential distribution with rate \( \lambda \), parameterized as \( f(x) = \lambda e^{-\lambda x} \) for \( x > 0 \) and \( \lambda > 0 \). The rate \( \lambda \) has a Gamma prior distribution with parameters \( \alpha \) and \( s \).

### Bayesian Credibility Model
The Bayesian credibility model provides that the posterior mean of \( 1/\lambda \) can be expressed as:

\[ \text{Posterior Mean of } \frac{1}{\lambda} = Z \cdot \frac{\sum x}{n} + (1 - Z) \cdot \frac{s}{\alpha - 1} \]

where \( Z = \frac{n}{\alpha + n - 1} \) and \( n \) is the number of past waiting times observed.

#### Parameters
- \( \alpha = 5 \)
- \( s = 1 \)

### Exercise 1: Estimate Posterior Mean for \( n = 10 \)

1. **Monte Carlo Setup**:
    ```r
    M = 3000
    n = 10
    alpha = 5
    s = 1
    pml = numeric(M)
    ```
2. **Calculate Posterior Mean**:
    ```r
    Z = n / (alpha + n - 1)

    for (i in 1:M) {
        lam = rgamma(1, alpha, s)
        x = rexp(n, lam)
        pml[i] = Z * sum(x) / n + (1 - Z) * s / (alpha - 1)
    }
    ```
3. **Get Results**:
    ```r
    head(pml)
    mean(pml)
    ```

This gives a point estimate of 0.248 for the mean of \( \frac{1}{\lambda} \).

### Exercise 2: Estimate Posterior Mean and Mean of \( x \) for \( n = 1000 \)

1. **Monte Carlo Setup**:
    ```r
    M = 3000
    n = 1000
    alpha = 5
    s = 1
    pml = numeric(M)
    mx = numeric(M)
    Z = n / (alpha + n - 1)
    ```
2. **Calculate Posterior Mean and Mean of \( x \)**:
    ```r
    for (i in 1:M) {
        lam = rgamma(1, alpha, s)
        x = rexp(n, lam)
        mx[i] = mean(x)
        pml[i] = Z * sum(x) / n + (1 - Z) * s / (alpha - 1)
    }
    ```
3. **Get Results**:
    ```r
    mean(pml)
    mean(mx)
    ```

Both estimates are equal to 0.245.

### Exercise 3: Plot Histograms

1. **Histograms**:
    ```r
    hist(pml, main = "Histogram of posterior means", xlab = "Posterior means", breaks=50)
    hist(mx, main = "Histogram of the distribution of the means of x", xlab = "mean of x", breaks=50)
    ```

### Exercise 4: Compare Distributions

- By visual inspection, compare the distributions of the posterior mean of \( 1/\lambda \) and the mean of \( x \) when \( n = 1000 \).

### Exercise 5: Comment on Behavior as \( n \) Increases

- **Conclusion**: As \( n \) increases, the credibility factor \( Z \) tends to 1. Therefore, the posterior mean of \( 1/\lambda \) becomes \( \bar{x} \), the sample mean of the waiting times.

I hope this helps! Let me know if you have any further questions or need additional clarification!
---

(i) Determine an estimate of the posterior mean of $1/l$ assuming $n = 10$ by
implementing M = 3,000 Monte Carlo repetitions. 

---

A Bayesian credibility model is a statistical method used to make informed predictions based on observed data and prior beliefs. It's particularly useful in insurance and actuarial science for estimating risks and premiums. Here’s a simple breakdown:

### Bayesian Approach
In the Bayesian framework, you combine prior information (prior distribution) with observed data (likelihood) to update your beliefs (posterior distribution).

1. **Prior Distribution**: Represents your initial beliefs or knowledge about a parameter before seeing the data.
2. **Likelihood**: Represents the probability of observing the data given a particular parameter.
3. **Posterior Distribution**: Represents your updated beliefs about the parameter after seeing the data. It is calculated using Bayes' Theorem:

\[ \text{Posterior} \propto \text{Likelihood} \times \text{Prior} \]

### Credibility Factor
In credibility theory, the credibility factor \( Z \) determines the weight given to the observed data versus the prior information. For example, if \( Z \) is close to 1, the model places more weight on the observed data. If \( Z \) is close to 0, it places more weight on the prior.

### Bayesian Credibility Model
A Bayesian credibility model specifically uses the Bayesian approach to update estimates of risk parameters (like claim frequency or severity) based on past data and prior information. It's called "credibility" because it quantifies how much "credibility" or weight to assign to the new data compared to prior beliefs.

#### Example
In your exercise, the model estimates the waiting time parameter \( \lambda \) using:
- An Exponential distribution for the waiting times.
- A Gamma prior distribution for \( \lambda \).

The posterior mean of \( 1/\lambda \) combines the observed data (past waiting times) with the prior distribution using a credibility factor \( Z \).

Bayesian credibility models help in making more accurate predictions by incorporating both historical data and expert judgment. They are widely used in fields where prior knowledge and data need to be harmonized, such as insurance, finance, and quality control.

I hope this clarifies what a Bayesian credibility model is! Let me know if you have any more questions.

#### Exercise 1

```{r}
M = 3000
n = 10
alpha = 5
s = 1
pml = numeric(M)
```
---


A Bayesian credibility model uses probability distributions, but it isn't itself a probability distribution. Instead, it's a statistical method used to update predictions or estimates about a parameter as new data becomes available. Let's break it down:

### **Bayesian Credibility Model**:

1. **Bayesian Inference**:
   - In Bayesian statistics, we start with a **prior distribution** that represents our initial beliefs about a parameter before observing any data.
   - As we collect data, we update our beliefs using **Bayes' theorem**, which combines the prior distribution with the **likelihood** of the observed data to produce a **posterior distribution**.

2. **Credibility Factor**:
   - In the context of credibility theory, the credibility factor (often denoted \( Z \)) is a weight that balances the influence of the prior information with the new data.
   - It is used to determine how much "credibility" to give to the new data versus the prior estimate.
   - The credibility factor is derived based on the amount of data observed; more data typically gives higher credibility to the new data.

3. **Posterior Mean**:
   - The **posterior mean** is an updated estimate of the parameter, calculated as a weighted average of the prior mean and the observed data, with weights determined by the credibility factor.
   - This combines prior knowledge and new evidence to provide a more accurate estimate.

### **Illustrative Example**:
Let's use the example from your Bayesian credibility model exercise:

- **Prior Distribution**: Gamma distribution for the rate \( \lambda \) with parameters \( \alpha = 5 \) and \( s = 1 \).
- **Likelihood**: Exponential distribution of waiting times \( X \) given \( \lambda \).

The posterior mean of \( \frac{1}{\lambda} \) (the mean waiting time) is calculated as:
$$
\text{Posterior Mean} = Z \cdot \bar{x} + (1 - Z) \cdot \frac{s}{\alpha - 1}
$$
where \( \bar{x} \) is the sample mean of the observed data.

### **Conceptual Understanding**:

- **Prior Distribution**: Represents your initial belief about \( \lambda \) before observing any waiting times.
- **Likelihood**: Represents the probability of observing the waiting times given a specific value of \( \lambda \).
- **Posterior Distribution**: Represents your updated belief about \( \lambda \) after observing the waiting times.
- **Credibility Factor \( Z \)**: Determines how much weight to give to the new data versus the prior information.

In summary, a Bayesian credibility model uses probability distributions to update estimates, but it is a method that leverages these distributions rather than being a distribution itself.

Would you like to dive deeper into any specific aspect of Bayesian models?
```{r}
Z = n/(alpha + n - 1) 

for (i in 1:M){ 
 lam = rgamma(1, alpha, s) 
 x = rexp(n, lam) 
 pml[i] = Z*sum(x)/n + (1-Z)*s/(alpha-1) 
 }
```

---

```{r}
head(pml)
```
 
```{r}
mean(pml)
```
A point estimate is given as the mean of the produced estimates, i.e.
#mean(pml) 
which gives 0.248. 
---
### Exercise 2

Determine an estimate of the posterior mean of $1/l$ and the value of x when
n = 1,000, by implementing M = 3,000 Monte Carlo repetitions. 

This time we use the same code as in (i) but we are recording the mean of x for the case n =
1000.

```{r}
M = 3000
n = 1000
alpha = 5
s = 1
pml = numeric(M)
mx = numeric(M)
Z = n/(alpha + n - 1)
```

---

```{r}
for (i in 1:M){
 lam = rgamma(1, alpha, s)
 x = rexp(n, lam)
 mx[i] = mean(x)
 pml[i] = Z*sum(x)/n + (1-Z)*s/(alpha-1)
}

```

---

```{r}
mean(pml)
mean(mx)
```

With this new run, both estimates are equal to 0.245.

---

### Exercise 3

Plot the histograms of the samples of the posterior mean of $1/l$ and of x
obtained in Part 2.


```{r eval=FALSE}
hist(pml, main = "Histogram of posterior means", xlab = "Posterior means")
hist(mx, main ="Histogram of the distribution of the means of x", 
xlab = "mean of x")

```
---

```{r echo=FALSE}
hist(pml, main = "Histogram of posterior means", 
 xlab = "Posterior means",
 breaks=50)
```
---

```{r echo=FALSE}
hist(mx, main ="Histogram of the distribution of the means of x", 
xlab = "mean of x",
breaks=50)

```
---

### Exercise 4

Compare, by visual inspection of the graphs in part (iii), the distributions
of the posterior mean of 1/l and the distribution of x when n = 1,000.

#### Conclusion

The distributions look identical.
---

### Exercise 5

Comment on the behaviour of the credibility model as n increases, relating
your answer to your findings in Exercise 4. 

#### Conclusion

We should expect that the distributions are the same, 
since the credibility factor $Z$ tends to 1 as $n$ increases and therefore the posterior mean of 1⁄𝜆𝜆
becomes $\bar{x}$.

---

END

---