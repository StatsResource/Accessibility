---
title: "Statistics with R"
subtitle: "Statistical Modelling with R for Actuarial Students"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(knitr)
library(dplyr)
library(janitor)


```

```{css, echo=FALSE}
pre {
  background: #ADD8E6;
  max-width: 100%;
  overflow-x: scroll;
}
```

***CS2B – Risk Modelling and Survival Analysis ***


* The emphasis is placed on being able to apply statistical methods to actuarial problems using real data sets and the open-source software environment R. 

* Time Series. Probability Distributions, Survival Analysis

---





Page 2 of 5
Q. 1)

---
i) Simulate a time series of length 500 observations in a line chart having following arguments:
Seed Value = 100
ar = 0.9
ma = 0.2
order = c(1,1,1)

ii) Comment on the general features of the chart.

iii) Plot the sample Autocorrelation Function (ACF) and sample Partial Autocorrelation function (PACF) of the data and paste the above graphs.

iv) Determine the best least squares linear fit, adding it to your chart in part (i) and paste the new chart.

v) Explain whether this least square linear trend can be removed such that stationary distribution is appropriate for the residuals.

vi) Fit an AR(1), AR and ARMA(1,1) model to the time series.

---

vii) Determine the corresponding 95% Confidence Interval for the AR(1) model fitted above.

viii) Mention the best fit model from your observations in part (vi). Calculate the predicted values using the best model fit above for 10 steps ahead.

ix) Construct the Autocorrelation Function (ACF) and sample Partial Autocorrelation function (PACF) for the residuals of the best fitted model above and plot the graph.

x) Comment on the graphical outputs of part (iii) and part (ix).

xi) Perform the Ljung and Box Portmanteau test for the residuals of the model with lag of 4, 6, 12 and comment whether the model is an appropriate fit.


---

Page 2 of 15
Solution 1:
i) 

```{r}
set.seed(100) 
observations <- arima.sim(
  list(order = c(1,1,1), ar = 0.9, ma = 0.2), n = 500)

#plot(observations, 
#     main = "Line chart of time series observation")

```


---

ii)
• The data is not stationary as we observe that the values are changing with time
• Downward trend is observed in the data and an upward trend towards the end, which indicates the data being non stationary
• Mean and Standard Deviation are different at different points in time , mean is not constant.

iii) 

```{r}
acf(observations, main = "ACF")
pacf(observations, main = "PACF")
```


---


iv) 

```{r}
x = 1:501 
```

```{r}
leastsquarefit <- lm(observations~x) 
leastsquarefit$coefficients 
```

(Intercept) x 10.0453231 -0.3941461 

```{r}
plot(observations, main = "Line chart of time series observation") 
abline(leastsquarefit)
```

---

### Part E


```{r}
plot(leastsquarefit$res, xlab = "Time" , ylab = "Residuals")
```

* It is clear that residuals are not stationary as they are negative in the first, then followed by positive residuals in the middle part and then negative in the last part.

--- 

Alternate Solution acf(leastsquarefit$res)
The residuals are not stationary as the ACF values are decaying very slowly.

---

### Part F
vi) 

```{r}
fit1 = arima(observations, order= c(1,0,0)) 
fit1 
#Call: arima(x = observations, order = c(1, 0, 0))
```

Coefficients: ar1 intercept 0.9997 -89.3179 s.e. 0.0004 85.5509 sigma^2 estimated as 5.091: log likelihood = -1122.25, aic = 
2250.5

---

fit2 = arima(observations, order= c(3,0,0)) 
fit2 

Call: arima(x = observations, order = c(3, 0, 0)) Coefficients: ar1 ar2 ar3 intercept 2.0064 -1.1350 0.1278 -89.0734 s.e. 0.0443 0.0864 0.0444 46.5760 sigma^2 estimated as 1.01: log likelihood = -718.61, aic = 1447.22

---

fit3 = arima(observations, order= c(1,0,1)) fit4 Call: arima(x = observations, order = c(1, 0, 1)) Coefficients: ar1 ma1 intercept 0.9996 0.7731 -89.3280 s.e. 0.0006 0.0210 83.2395 sigma^2 estimated as 2.128: log likelihood = -904.58, aic = 1817.16

---


vii) 
```{r}
fit1$coef[1] - qnorm(0.975)*sqrt(fit1$var.coef[1,1]) 
#ar1 
#0.998827 
fit1$coef[1] + qnorm(0.975)*sqrt(fit1$var.coef[1,1]) 
#ar1 1.000529
```
The confidence interval is ( 0.998827 , 1.000529 )


### Part G
viii)
The AIC is lowest for AR among the models above and hence is the best fit among the above models. predict(fit2, n.ahead = 10) $pred

Time Series: Start = 502 End = 511 Frequency = 1 [1] -181.5409 -180.3970 -179.3290 -178.3314 -177.3959 -176.5145 -175.6804 -174.8877 -174.1311 [10] -173.4062 $se Time Series: Start = 502 End = 511 Frequency = 1 [1] 1.005205 2.253488 3.677225 5.195037 6.758213 8.335575 9.906391 11.456656 12.976922 [10] 14.460927
[2]
ix) par(mfrow = c(1,2)) acf(fit2$residuals) pacf(fit2$residuals)
[2]
x)
PACF for the data shows no significance from lag 2 which could indicate stationarity but the ACF is decaying very slowly indicating it is not stationary. For example, this is consistent with ARIMA (1,1,1) behaviour.
The plot for the residuals generally lies within the confidence intervals. This is consistent with the residuals forming the white noise process.
[2]
xi) Box.test(fit2$residuals, type = "Ljung", fitdf = 3, lag = 4) Box-Ljung test data: fit2$residuals X-squared = 5.8414, df = 1, p-value = 0.01565
IAI CS2B-1123
Page 7 of 15
Box.test(fit2$residuals, type = "Ljung", fitdf = 3, lag = 6) Box-Ljung test data: fit2$residuals X-squared = 8.3718, df = 3, p-value = 0.03892 Box.test(fit2$residuals, type = "Ljung", fitdf = 3, lag = 12) Box-Ljung test data: fit2$residuals X-squared = 17.565, df = 9, p-value = 0.04057
• The result above suggests that the residuals are forming a white noise process suggesting a good fit for ARIMA(3,0,0) model,
• The result above also suggests that the model requires differencing as it is consistent with ARIMA(p,1,q) behaviour.
• However, the three tests are not consistent with an ARIMA(3,0,0) model at the 5% significance level, since the p-values are lesser than 0.05
• Thus, there is not enough evidence to conclude ARIMA(3,0,0) to be a good fit.
• Also, we would expect the ARIMA(1,1,1) model that was used to generate the data to satisfy this test as well and thus can be shown to be also a good fit.
[5]
[28 Marks]
