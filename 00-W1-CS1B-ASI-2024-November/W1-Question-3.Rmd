---
title: "Statistics with R"
subtitle: "Introduction to R for Actuarial Students"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(knitr)
library(dplyr)
library(janitor)


```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_mono_accent_inverse(
  #base_color = "#3C989E")(
  base_color = "#1c5253",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_google   = google_font("Fira Mono")
)
```


* Introduction to R for Actuarial Students

* CS1B Curriculum

 - Introduction to R programming
 -  Fundamentals of Statistical Analysis


### Exercise

This exercise involves analyzing and modeling data collected from a National Sports Meet, where 27 states participated across various sports categories.

---

 The tasks include:

1. **Multiple Regression Model**: Fit a multiple regression model to predict winning points based on scores in nine sports events, identify significant predictors, and visualize the residuals.

2. **Generalized Linear Model (GLM)**: Fit a GLM using a Poisson distribution, report the estimated coefficients and AIC, and compare the fit with the multiple regression model using AIC.

3. **Principal Components Analysis (PCA)**: Perform PCA for three categories of sports (Running, Jumping, and Throwing) to determine the variance captured by the first principal component for each category.

4. **Correlation Test**: Test the correlation between pole vault points and overall winning points, and calculate a 95% confidence interval for the slope coefficient.

5. **Predictive Modeling**: Fit a linear regression model to predict 110m hurdle race scores based on 100m trial scores and use it to estimate missing scores for the last five runners.

Each step involves using statistical techniques and R programming to analyze the data and draw meaningful conclusions to aid in preparing for international events.

---

### National Sports Meet Data

* The dataset titled "***Sports.csv***" contains performance data from a National Sports Meet where 27 states participated. 

* The data includes scores from various athletic events and the overall winning points for each participant. 

* Each row represents an individual participant's performance across different events. 


---

### Variables

The columns in the dataset are as follows:

1. **X100m**: Time taken to complete the 100 meters sprint.

2. **Long.jump**: Distance covered in the long jump event.

3. **Shot.put**: Distance covered in the shot put event.

4. **High.jump**: Height achieved in the high jump event.

5. **X400m**: Time taken to complete the 400 meters race.

6. **X110m.hurdle**: Time taken to complete the 110 meters hurdle race.

7. **Discus**: Distance covered in the discus throw event.

8. **Pole.vault**: Height achieved in the pole vault event.

9. **Javeline**: Distance covered in the javelin throw event.

10. **Points**: Total winning points accumulated by the participant based on their performance in the above events.

---

### Reading in Data

```{r warning=FALSE,message=FALSE}
# Load necessary library
library(readr)

# Read the data
sports_data <- read_csv("Sports.csv")

```

---

### Inspecting the data

```{r}

head(sports_data)

```
---

### Exercise 1

(a) Fit a multiple regression model between winning points (as the response variable) and 
the scores in the nine sports (as explanatory variables). Display the summary of the fitted 
model and identify which explanatory variables are significant at 5% level of 
significance.   
 
(b) Prepare a plot of the residuals of the multiple regression model.  


---


### Exercise 1

**Fit a multiple regression model**

* First, we'll fit a multiple regression model. 

* We'll then display the summary of the fitted model to identify significant explanatory variables at the 5% level of significance.




### Model Fitting

```{r}

# Fit the multiple regression model
model <- lm(Points ~ X100m + Long.jump + Shot.put + High.jump + X400m + 
                    X110m.hurdle + Discus + Pole.vault + Javeline, 
            data = sports_data)


```


```{r eval = FALSE}
# Display the summary of the model
summary(model)
```

---



```{r echo=FALSE}
# Display the summary of the model
summary(model)
```

---

### Exercise 1 

**Model Fitting**

* Using a general rule if the p-value is less than  0.05, then the concerned explanatory variable 
is considered to be significant. 

* This is shown by <tt>\*</tt>, <tt>\*\*</tt>, <tt>\*\*\*</tt> signs in the R summary output . 

* So, based on the R-output, only points for ***Discus Throw*** are not significant. 

* All other explanatory variables are considered to be significant.  



---

### Exercise 1

**Plot the residuals**
We will prepare a residuals plot for the multiple regression model.

```{r eval=FALSE}
# Plot residuals
plot(model$residuals, 
     main = "Residuals of the Multiple Regression Model", 
     ylab = "Residuals", 
     xlab = "Index",
     pch  = 16)

abline(h = 0, col = "red", lty = 2)
```

---

```{r echo=FALSE}
# Plot residuals
plot(model$residuals, 
     main = "Residuals of the Multiple Regression Model", 
     ylab = "Residuals", 
     xlab = "Index",
     pch  = 16)

abline(h = 0, col = "red", lty = 2)
```


---

### Exercise 2

**Fit a Generalised Linear Model (GLM)**

Here we'll fit a Generalised Linear Model (GLM) assuming a Poisson distribution for the response variable and include the estimated coefficients and the Akaikeâ€™s Information Criteria (AIC) of the fitted model.

```{r}
# Fit the Generalized Linear Model (GLM)
glm_model <- glm(Points ~ X100m + Long.jump + Shot.put + High.jump + X400m + 
						  X110m.hurdle + Discus + Pole.vault + Javeline, 
						  family = poisson(link = "log"), 
						  data = sports_data)

```


```{r eval=FALSE}
summary(glm_model) 

```

---


```{r echo=FALSE}
summary(glm_model) 

```

---


```{r}

# Display the AIC of the GLM
AIC(glm_model)
```

---

### Exercise 3

**Explain why scaled deviance cannot be used to compare the fit of the models in exercises 1 and 2**

* Scaled deviance is a measure of goodness of fit for models, but it is model-specific. 

* In exercise 1, we used a linear regression model, and in exercise 2, we used a Poisson GLM. 

* These models have different assumptions and distributions (normal vs. Poisson). 

* Therefore, the scaled deviance from the Poisson GLM cannot be directly compared with the residual sum of squares or other goodness-of-fit measures from the linear regression model because they are based on different likelihood functions and error distributions.


---
### Exercise 4

**Fit a GLM equivalent to the multiple regression model**

To fit a GLM equivalent to the multiple regression model (which assumes a Gaussian distribution for the response variable), we can use the `family = gaussian` argument.

```{r}
# Fit the GLM equivalent to the multiple regression model
glm_model_gaussian <- glm(
  Points ~ X100m + Long.jump + Shot.put + High.jump + X400m + 
           X110m.hurdle + Discus + Pole.vault + Javeline, 
  family = gaussian(link = "identity"), 
  data = sports_data)
```

---

```{r echo=FALSE}
# Display the summary of the GLM
summary(glm_model_gaussian)
```

---

### Exercise 4

**AIC**

```{r}
# Display the AIC of the GLM
AIC(glm_model_gaussian)
```

---

### Exercise 5

**Compare the fit of the models using AIC**

We will compare the AIC values of the models fitted in exercises 1 and 2.

```{r}
# AIC of the multiple regression model (exercise 1)
aic_multiple_regression <- AIC(model)

# AIC of the GLM with Poisson distribution (exercise 2)
aic_poisson_glm <- AIC(glm_model)

# Compare the AIC values
cat("AIC of the multiple regression model:", aic_multiple_regression, "\n")
cat("AIC of the Poisson GLM:", aic_poisson_glm, "\n")
```

---

### Exercise 6

**Perform Principal Components Analysis**

Perform Principal Components Analysis (PCA) separately for the above three categories 
of sports viz. Running Sports, Jumping Sports and Throwing Sports and share how much 
variation is captured by first principal component (PC1) for each category. 
 
[Hint: Use <tt>prcomp()</tt> and do scaling by using <tt>scale.=TRUE</tt> parameter.] 

---
### Exercise 6

**Perform Principal Components Analysis (PCA)**

We will perform PCA separately for each sports category (Running, Jumping, and Throwing) and share how much variation is captured by the first principal component (PC1).


#### Running Sports

```{r}
# Perform PCA for Running Sports
pca_running <- prcomp(
  sports_data[, c("X100m", "X400m", "X110m.hurdle")], 
  scale. = TRUE)

summary(pca_running)
```

---

#### Jumping Sports

```{r}
# Perform PCA for Jumping Sports
pca_jumping <- prcomp(
  sports_data[, c("High.jump", "Long.jump", "Pole.vault")], 
  scale. = TRUE)

summary(pca_jumping)

```

---

#### Throwing Sports

```{r}
# Perform PCA for Throwing Sports
pca_throwing <- prcomp(
  sports_data[, c("Shot.put", "Javeline", "Discus")], 
  scale. = TRUE)

summary(pca_throwing)
```

---

### Exercise 6


* For Running Sports Category, 74.2% variance is captured by PC1. 

* For Jumping Sports Category, 52.82% variance is captured by PC1. 

* For Throwing Sports Category, 66.65% variance is captured by PC1. 

---

### Exercise 7.

Under which sports category, principal components will be most useful in reducing 
dimensionality of the dataset while capturing 90% of variance? 

---

### Exercise 7.

**Determine the most useful category for PCA in reducing dimensionality**

* By examining the summaries of the PCA results, we can determine which sports category has the highest variance captured by the first principal component, and thus which is most useful in reducing dimensionality while capturing 90% of variance.

 
 
 - In case of Running Sports Category, all three PCs cumulatively capture at least 90% of the total 
variance of the data. 
 
 - In case of Jumping Sports Category, all three PCs cumulatively capture at least 90% of the total 
variance of the data. 
 
 - In case of Throwing Sports Category, first two PCs cumulatively capture 92.04% (at least 90%) 
of the total variance of the data. 

---

### Exercise 7.

* So, if PCs capturing at least 90% of the variance is a criterion for reducing the dimensionality 
of the data set, then Throw Sports Category satisfies it. 

* For Throw Sports, PC1 and PC2 can 
be retained and PC3 can be dropped thus reducing the dimensionality of the data set.

* In case 
of Run Sports and Jumping Sports, all three PCs need to be retained and thus the 
dimensionality of the data set will not be reduced.  

---

### Exercise 8

* The organisers informed that pole vault sports winning points are not properly captured. 

* Test whether there is any correlation between pole vault points and overall winning points 
by calculating a 95% confidence interval for the Slope Coefficient Beta.

* Clearly state the 
null and alternative hypotheses and the conclusion of the test.  

---
### Exercise 8

**Test correlation between pole vault points and overall winning points**

We will calculate a 95% confidence interval for the slope coefficient (Beta) to test the correlation.

```{r}
# Fit the linear regression model for pole vault points and overall winning points
lm_polevault <- lm(Points ~ Pole.vault, data = sports_data)
```

---

```{r}
# Display the summary of the model
summary(lm_polevault)

```

---

### Exercise 8

**Null Hypothesis ($H_0$)**: There is no correlation between pole vault points and overall winning points (Beta = 0).

**Alternative Hypothesis ($H_1$)**: There is a correlation between pole vault points and overall winning points (Beta â‰  0).

 
   
 

---

### Exercise 8

```{r}
# Calculate the 95% confidence interval for the slope coefficient
confint(lm_polevault, level = 0.95)
```

* As the 95% confidence interval for beta (-573.3559, 508.9277) contains the value 0, we do 
not have sufficient evidence to reject the null hypothesis at 5% level of significance. 

* Hence, 
based on this test, one can conclude that there is no correlation between pole vault score and 
winning points. 


---

### Exercise 9

Players for racing sports have now been shortlisted for the international event and trials 
have started for the upcoming international event. However due to unforeseen 
circumstances, trials for 110 metres hurdle race got cancelled for last 5 runners. An 
analyst suggests that their scores can be predicted using their 100m trial scores. 
 
Below are the 100 metres scores of last 5 runners. 
1. 10.68 
2. 10.42 
3. 11.68 
4. 11.62 
5. 10.54 
 
**Tasks**

Fit a linear regression model to predict the scores in 110 metres hurdle race using scores 
in 100 metres race as the explanatory variable using the national sports meet data. 

Clearly state the equation of this linear regression model. 

Using this equation, predict the expected 110m hurdle race scores of the last five runners.

---

### Exercie 9

**Predict 110m hurdle race scores using 100m trial scores**

We will fit a linear regression model and predict the scores for the last five runners.

```{r}
# Fit the linear regression model for 110m hurdle race using 100m trial scores
lm_100m_to_110mhurdle <- lm(X110m.hurdle ~ X100m, data = sports_data)
```
<br>

```{r eval=FALSE}
# Display the summary of the model
summary(lm_100m_to_110mhurdle)
```
---


```{r echo=FALSE}
# Display the summary of the model
summary(lm_100m_to_110mhurdle)
```

---

### Exercie 9

```{r}
# 100m trial scores of the last 5 runners
last_5_runners_100m <- data.frame(X100m = c(10.68, 10.42, 11.68, 11.62, 10.54))

# Predict the 110m hurdle race scores
predicted_110m_hurdle_scores <- predict(lm_100m_to_110mhurdle, newdata = last_5_runners_100m)
predicted_110m_hurdle_scores
```

---

The linear regression model equation would be of the form:
$$\text{X110m.hurdle} = \beta_0 + \beta_1 \times \text{X100m}$$

Where $\beta_0$ is the intercept and $\beta_1$ is the slope coefficient obtained from the model summary.

---

---

Running the above R code will help you perform the required analyses and predictions. If you have further questions or need additional explanations, 

Call: 
lm(formula = Sports$Points ~ Sports$X100m + Sports$X400m + Sports$X110m.hurdle +  
Sports$High.jump + Sports$Long.jump + Sports$Pole.vault +  
Sports$Shot.put + Sports$Javeline + Sports$Discus) 
Residuals: 
Min      1Q  Median      3Q     Max  -97.106 -25.043  -7.748  33.856 119.528  
Coefficients: 
Estimate Std. Error t value Pr(>|t|)     
(Intercept)         
8632.632   1368.083   6.310 7.83e-06 *** 
Sports$X100m        
Sports$X400m         -163.414     76.208  -2.144 0.046756 *   -78.141     16.269  -4.803 0.000166 *** 
Sports$X110m.hurdle -120.901     41.818  -2.891 0.010152 *   
Sports$High.jump     810.196    211.532   3.830 0.001340 **  
Sports$Long.jump     209.187     63.472   3.296 0.004269 **  
Sports$Pole.vault    183.345     66.876   2.742 0.013912 *   
Sports$Shot.put       
90.349     28.200   3.204 0.005204 **  
Sports$Javeline       
Sports$Discus         
17.757      
10.986      
2.975   5.969 1.52e-05 *** 
5.781   1.900 0.074491 .   --- 
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 
Residual standard error: 60.74 on 17 degrees of freedom 
Multiple R-squared:  0.9794, 
Adjusted R-squared:  0.9685  
F-statistic: 89.91 on 9 and 17 DF,  p-value: 1.491e-12 

#b Plot of residuals for the model  
ii) 
  
residuals(Model1)
 0 50-100
 0
 5
 10
 15
 Index
 20
 25
 > Model2_poisson<-glm(Sports$Points~Sports$X100m+Sports$X400m+Sports$X110m.hurd
 le+Sports$High.jump+Sports$Long.jump+Sports$Pole.vault+Sports$Shot.put+Sports$Javelin
 e+Sports$Discus,family="poisson") 
> summary(Model2_poisson)  
Call: 
glm(formula = Sports$Points ~ Sports$X100m + Sports$X400m + Sports$X110m.hurdle +  
Sports$High.jump + Sports$Long.jump + Sports$Pole.vault +  
Sports$Shot.put + Sports$Javeline + Sports$Discus, family = "poisson") 
Deviance Residuals:   
(6) 
(2) 
Page 6 of 11 
IAI                             
CS1B-1124 
Min        
1Q    Median        
3Q       Max   -1.02319  -0.25491   0.03473   0.36449   1.31328   
Coefficients: 
(Intercept)          
Estimate Std. Error z value Pr(>|z|)     
9.0988649  0.2501151  36.379  < 2e-16 *** 
Sports$X100m        
Sports$X400m        -0.0211126  0.0139153  -1.517  0.12921     -0.0093734  0.0029665  -3.160  0.00158 **  
Sports$X110m.hurdle -0.0161147  0.0076612  -2.103  0.03543 *   
Sports$High.jump     0.1009034  0.0387525   2.604  0.00922 **  
Sports$Long.jump     0.0239972  0.0116951   2.052  0.04018 *   
Sports$Pole.vault    0.0225249  0.0122296   1.842  0.06550 .   
Sports$Shot.put      
0.0111537  0.0051471   2.167  0.03024 *   
Sports$Javeline      
Sports$Discus        
0.0021487  0.0005379   3.995 6.48e-05 *** 
0.0012340  0.0010555   1.169  0.24236     --- 
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 
(Dispersion parameter for poisson family taken to be 1) 
Null deviance: 374.4158  on 26  degrees of freedom 
Residual deviance:   8.3483  on 17  degrees of freedom 
AIC: 321 
Number of Fisher Scoring iterations: 3 
iii) 
iv) 
Scaled deviance can be used to compare only nested models.  
Since, Model 1 and Model2_Poisson are models with different distributional assumptions. 
Model 1 assumes normal distribution and Model 2 assumes Poisson distribution.  
They are not nested models. 
Hence, scaled deviance cannot be used to compare the models in parts (i) and (ii). 
An equivalent model to a linear regression model will be a GLM with normal distribution.   
> Model2_normal<-glm(Sports$Points~Sports$X100m+Sports$X400m+Sports$X110m.hurdl
 e+Sports$High.jump+Sports$Long.jump+Sports$Pole.vault+Sports$Shot.put+Sports$Javelin
 e+Sports$Discus,family=gaussian()) 
> summary(Model2_normal)  
Call: 
glm(formula = Sports$Points ~ Sports$X100m + Sports$X400m + Sports$X110m.hurdle +  
Sports$High.jump + Sports$Long.jump + Sports$Pole.vault +  
Sports$Shot.put + Sports$Javeline + Sports$Discus, family = gaussian()) 
Deviance Residuals:  
Min       
1Q   Median       3Q      Max   -97.106  -25.043   -7.748   33.856  119.528   
Coefficients: 
Estimate Std. Error t value Pr(>|t|)     
(Intercept)         
8632.632   1368.083   6.310 7.83e-06 ***  
(4) 
(2) 
Page 7 of 11 
IAI                             
CS1B-1124 
Sports$X100m        
Sports$X400m         -163.414     76.208  -2.144 0.046756 *   -78.141     16.269  -4.803 0.000166 *** 
Sports$X110m.hurdle -120.901     41.818  -2.891 0.010152 *   
Sports$High.jump     810.196    211.532   3.830 0.001340 **  
Sports$Long.jump     209.187     63.472   3.296 0.004269 **  
Sports$Pole.vault    183.345     66.876   2.742 0.013912 *   
Sports$Shot.put       
90.349     28.200   3.204 0.005204 **  
Sports$Javeline       
Sports$Discus         
17.757      
10.986      
2.975   5.969 1.52e-05 *** 
5.781   1.900 0.074491 .   --- 
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 
(Dispersion parameter for gaussian family taken to be 3689.4) 
Null deviance: 3048179  on 26  degrees of freedom 
Residual deviance:   62720  on 17  degrees of freedom 
AIC: 307.89 
Number of Fisher Scoring iterations: 2 
v) 
vi) 
Model 1 in exercise 1 and Model 2 (Normal) in part (iv) are exact equivalents of each other. The 
same can be seen from the estimates of coefficients in the R summary output. 
So, for comparing the fit of Model 1 and Model 2 (Poisson), Model 2 (Normal) can be used as 
a proxy for Model 1. And then, the AIC of Model 2 (Poisson) can be compared with the AIC 
of Model 2 (Normal). 
AIC (Model 2 Normal) = 307.89 
AIC (Model 2 Poisson) = 321 
Smaller the AIC, better is the fit. So, Model 2 Normal is a better fit as compared to Model 2 
Poisson.  
Consequentially, the linear multiple regression model in exercise 1 is a better fit to the data as 
compared to the GLM fitted in exercise 2. 
> run<-data.frame(Sports$X100m,Sports$X400m,Sports$X110m.hurdle) 
> pr_run<-prcomp(run,scale. = TRUE) 
>  
> summary(pr_run) 
Importance of components: 
PC1    PC2    PC3 
Standard deviation     1.492 0.6680 0.5726 
Proportion of Variance 0.742 0.1487 0.1093 
Cumulative Proportion  0.742 0.8907 1.0000 
>  
> jump<-data.frame(Sports$High.jump,Sports$Long.jump,Sports$Pole.vault) 
> pr_jump<-prcomp(jump,scale. = TRUE) 
>  
> summary(pr_jump) 
Importance of components: 
PC1    PC2    PC3  
(4) 
(2) 
Page 8 of 11 
IAI                             CS1B-1124 
     Page 9 of 11 
 
Standard deviation     1.2588 1.0307 0.5941 
Proportion of Variance 0.5282 0.3541 0.1176 
Cumulative Proportion  0.5282 0.8824 1.0000 
  
>  
> throw<-data.frame(Sports$Shot.put,Sports$Javeline,Sports$Discus) 
> pr_throw<-prcomp(throw,scale. = TRUE) 
>  
> summary(pr_throw) 
Importance of components: 
                          PC1    PC2     PC3 
Standard deviation     1.4141 0.8727 0.48853 
Proportion of Variance 0.6665 0.2539 0.07955 
Cumulative Proportion  0.6665 0.9204 1.00000  
  
For Run Sports Category, 74.2% variance is captured by PC1. 
For Jumping Sports Category, 52.82% variance is captured by PC1. 
For Throw Sports Category, 66.65% variance is captured by PC1.  (7) 
   
vii) Considering the summary R output generated in part (vi),  
 
In case of Run Sports Category, all three PCs cumulatively capture at least 90% of the total 
variance of the data. 
 
In case of Jump Sports Category, all three PCs cumulatively capture at least 90% of the total 
variance of the data. 
 
In case of Throw Sports Category, first two PCs cumulatively capture 92.04% (at least 90%) 
of the total variance of the data. 
 
So, if PCs capturing at least 90% of the variance is a criterion for reducing the dimensionality 
of the data set, then Throw Sports Category satisfies it. For Throw Sports, PC1 and PC2 can 
be retained and PC3 can be dropped thus reducing the dimensionality of the data set. In case 
of Run Sports and Jumping Sports, all three PCs need to be retained and thus the 
dimensionality of the data set will not be reduced.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(3) 
   
viii) > Model3<-lm(Sports$Points~Sports$Pole.vault)  
  
H0: Beta coefficient is equal to 0 
H1: Beta coefficient is not equal to 0.   
   
 > confint(Model3,level=0.95) 
                      2.5 %     97.5 % 
(Intercept)       5654.3838 10895.1124 
Sports$Pole.vault -573.3559   508.9227  
   
 As the 95% confidence interval for beta (-573.3559, 508.9277) contains the value 0, we do 
not have sufficient evidence to reject the null hypothesis at 5% level of significance. Hence, 
based on this test, one can conclude that there is no correlation between pole vault score and 
winning points.  (5) 
   
ix) > Model4<-lm(Sports$X110m.hurdle~Sports$X100m) 
> summary(Model4) 
  
IAI                             CS1B-1124 
     Page 10 of 11 
 
Call: 
lm(formula = Sports$X110m.hurdle ~ Sports$X100m) 
 
Residuals: 
     Min       1Q   Median       3Q      Max  -0.48075 -0.28936 -0.05353  0.21428  0.76203  
 
Coefficients: 
             Estimate Std. Error t value Pr(>|t|)     
(Intercept)    2.2036     2.7252   0.809 0.426379     
Sports$X100m   1.1183     0.2478   4.512 0.000132 *** --- 
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 
 
Residual standard error: 0.356 on 25 degrees of freedom 
Multiple R-squared:  0.4489, Adjusted R-squared:  0.4268  
F-statistic: 20.36 on 1 and 25 DF,  p-value: 0.0001319 
  
> score<-c(10.68,10.42,11.68,11.62,10.54) 
> hurdle_score<-2.2036+1.1183*score 
> hurdle_score 
[1] 14.14704 13.85629 15.26534 15.19825 13.99048  
  (5) 
  [40] 
   