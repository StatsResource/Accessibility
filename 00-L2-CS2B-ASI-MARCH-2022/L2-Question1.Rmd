---
title: "Statistics with R"
subtitle: "Introduction to R for Actuarial Students"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(knitr)
#library(dplyr)
library(janitor)


```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_mono_accent_inverse(
  #base_color = "#3C989E")(
  base_color = "#1c5253",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_google   = google_font("Fira Mono")
)
```
***CS2B â€“ Risk Modelling and Survival Analysis ***


* The emphasis is placed on being able to apply statistical methods to actuarial problems using real data sets and the open-source software environment R. 

* Time Series. Probability Distributions, Survival Analysis

---

Q. 1) A statistician uses Decision Tree to reach the final decision of whether there is a need to 
conduct a surgery for a patient or not. This is based on testing the presence of three parameters 
in human body. You need to test the effectiveness of the decision tree in predicting the need 
for surgery correctly.
Below is the decision tree as shown:


---

### Exercises

A. Write a function in R to decide whether a surgery is needed or not based on the value of 
three parameters. Denote Surgery required as 1 and Surgery not required as 0. 

B. Check the value of function with parameter 1=180, parameter 2=75, parameter 3=350 

C. Load <tt>CS2B_Mar22_Dataset1.csv<tt> file into R and name it as decisionData. This data 
contains the three parameter values for 50 patients and the actual decision taken with 
respect to the surgery. Apply the function created in Part A to this data. Paste the output after 
applying the function in your answer sheet. 

D. Compare the predicted and actual decisions by computing precision, recall and F1 score. 

E. Comment on the results obtained in Part D. 

---
Solution 1:

### Part A

```{r}
library(moments)
# i)
f=function(x){
 ifelse(x[1]>150 & x>50,ifelse(x[3]>300,1,0),0)
}

```


```{r}
#OR
f=function(x){
ifelse(x[1]>150 & x>50,0,ifelse(x[3]>300,1,0))
}

```


```{r}
#OR
f=function(x){
ifelse(x[1]>150 & x>50,ifelse(x[3]>300,0,1),0)
}

```


```{r}

f=function(x){
ifelse(x[1]>150 & x>50,0,ifelse(x[3]>300,0,1))
}
```

---

### Part B.

```{r}
f(c(180,75,350))

```

---

#### Part C.

```{r}
decisionData=read.csv("CS2B_Mar22_Dataset1.csv")
model=apply(decisionData,1,f)
model
```


---

#### Part D.

```{r}
TP=sum(model == 1 & decisionData$OperationStatus == 1)
print(paste("TP = ", TP))
## [1] "TP = 8"
FP=sum(model == 1 & decisionData$OperationStatus == 0)
print(paste("FP = ", FP))
## [1] "FP = 5"
TN=sum(model == 0 & decisionData$OperationStatus == 0)
print(paste("TN = ", TN))

```

---

```{r}
FN=sum(model == 0 & decisionData$OperationStatus == 1)
print(paste("FN = ", FN))

```


```{r}
precision=(TP/(TP+FP))
precision 


```

---

```{r}
recall=(TP/(TP+FN))
recall


f1=(2*precision*recall)/(precision+recall)
f1 

```

---

#### Part E.

* Lower precision value indicates the presence of larger number of False positives

* Lower recall value indicates the presence of larger number of False negatives

* This test is not really effective at correctly identifying individuals who require Surgery

* F1 tells how precise your classifier is (how many instances it classifies correctly), as well as how robust it is (it does not miss a significant number 
of instances)

* Low F1 score indicates that the model can be modified to increase its performance

---


**Part A: Writing the Decision Tree Function in R**

```R
decision_tree <- function(param1, param2, param3) {
  if (param1 > 150) {
    if (param2 > 70) {
      return(1)  # Surgery required
    } else {
      return(0)  # Surgery not required
    }
  } else {
    if (param3 > 300) {
      return(1)  # Surgery required
    } else {
      return(0)  # Surgery not required
    }
  }
}
```

**Part B: Checking Function Value**

```R
result <- decision_tree(180, 75, 350)
print(result)  # Output: 1 (Surgery required)
```

**Part C: Applying the Function to the Dataset**

```R
# Load the data
decisionData <- read.csv("CS2B_Mar22_Dataset1.csv")

# Apply the function to each row
decisionData$predicted_decision <- apply(decisionData[, 1:3], 1, function(x) decision_tree(x[1], x[2], x[3]))

# Print the data with predicted decisions
print(decisionData)
```

**Part D: Evaluating the Model**

```R
# Calculate confusion matrix
confusion_matrix <- table(decisionData$Actual_Decision, decisionData$predicted_decision)

# Calculate precision, recall, and F1-score
precision <- confusion_matrix[2,2] / (confusion_matrix[2,2] + confusion_matrix[1,2])
recall <- confusion_matrix[2,2] / (confusion_matrix[2,2] + confusion_matrix[2,1])
f1_score <- 2 * (precision * recall) / (precision + recall)

print(paste("Precision:", precision))
print(paste("Recall:", recall))
print(paste("F1-score:", f1_score))
```

**Part E: Commenting on the Results**

The precision, recall, and F1-score provide insights into the model's performance.

* **Precision:** Measures the proportion of positive predictions that are actually positive.
* **Recall:** Measures the proportion of actual positive cases that are correctly identified.
* **F1-score:** Balances precision and recall.

By analyzing these metrics, we can assess how well the decision tree model is performing in predicting the need for surgery. A higher F1-score indicates a better-performing model. 

However, it's important to note that the effectiveness of the model can be influenced by various factors, such as the quality and quantity of the training data, the complexity of the decision tree, and the underlying medical conditions. To improve the model's performance, consider exploring more advanced techniques like machine learning algorithms or consulting with domain experts to refine the decision rules.
