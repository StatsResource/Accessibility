---
title: "Statistics with R"
subtitle: "Statistical Modelling with R for Actuarial Students"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(knitr)
library(dplyr)
library(janitor)


```

```{css, echo=FALSE}
pre {
  background: #ADD8E6;
  max-width: 100%;
  overflow-x: scroll;
}
```

***CS2B – Risk Modelling and Survival Analysis ***


* The emphasis is placed on being able to apply statistical methods to actuarial problems using real data sets and the open-source software environment R. 

* Time Series. Probability Distributions, Survival Analysis

---
CS2B S2022–5
3 The dataset ‘CS2B_S22_Qu_3_Data.csv’ contains the following four variables: mpg,
disp, qsec, hp.
You are tasked to build a regression model to explain the response, hp, in terms of the
features mpg, disp and qsec. Thus, the model must be in the form:
yi = $\beta$0 + $\beta$1*mpgi + $\beta$2*dispi + $\beta$3*qseci + εi
where $\beta$0, $\beta$1, $\beta$2 and $\beta$3 are the regression parameters and ε represents the error term.
This model can be written compactly as:
y = X $\beta$ + ε
where y is the vector containing the response data and X is the design matrix.

---

(i) Write R code to load the dataset ‘CS2B_S22_Qu_3_Data.csv’ into R, create
the design matrix, X, including column headings and display the first six rows
of this design matrix.
[Note: The X you create must be of the type ‘matrix’.] 
You would like to fit the above model by minimizing the following:
||y – X $\beta$||2 +
$\lambda$
2 ||$\beta$||2
It can be shown that, for a given value of $\lambda$, the estimate $\beta$$\lambda$ of $\beta$ that minimises the
expression above is such that:
􁈺Xt X + $\lambda$*I􁈻 $\beta$$\lambda$ = Xt y
where I is the identity matrix and Xt is the transpose of X.
(ii) State the name of this modelling approach. 
(iii) Construct an R function, ridge_fit, that takes as inputs the value of $\lambda$, the
vector of response data and the design matrix, and then returns the value of
$\beta$$\lambda$ = 􁈺Xt X + $\lambda$*I􁈻–1 Xt y.
[Hint: The R function solve can be used to compute the inverse of a matrix.
That is, for a given invertible matrix, M, its inverse, M–1, can be computed in
R by running the following code: solve(M).] 

---

(iv) Calculate and display the value of the vector $\beta$2 (i.e. the value of vector $\beta$$\lambda$ for
$\lambda$ = 2). 
(v) Construct R code to compute the values of the vectors $\beta$$\lambda$ and store them into
successive rows of a matrix named matrix_LAMBDA, for $\lambda$ = i/10, where
i = 0, 1, 2, ..., 10,000. 

--- 

(vi) Display the top six rows of <tt>matrix_LAMBDA</tt>. 
You would like to select the best value of $\lambda$. A senior statistician suggests that you
should base your selection on a statistical information criterion. However, most
statistical information criteria depend on the so-called effective dimension of the
model. For this task, it can be shown that the effective dimension is the sum of the
diagonal elements of the following matrix: X(XtX + $\lambda$*I)–1Xt.

---

(vii) Construct an R function called <tt>dim_fit</tt> that takes as inputs the design
matrix and the value of $\lambda$, and then returns the corresponding effective
dimension. 
(viii) Construct R code to compute the values of the effective dimensions and store
them in a vector called vector_dim, for $\lambda$ = i/10, where
i = 0, 1, 2, ..., 10,000. 
(ix) Plot the effective dimension as a function of $\lambda$. 
(x) Comment on your plot from part (ix). 


---


**Part (i) Loading Data and Creating Design Matrix**

```R
# Load the data
data <- read.csv("CS2B_S22_Qu_3_Data.csv")

# Create the design matrix
X <- cbind(rep(1, nrow(data)), data[, c("mpg", "disp", "qsec")])
colnames(X) <- c("Intercept", "mpg", "disp", "qsec")

# Display the first six rows
head(X)
```

**Part (ii) Name of the Modelling Approach**

This modelling approach is called **Ridge Regression**.

**Part (iii) Ridge Regression Function**

```R
ridge_fit <- function(lambda, y, X) {
  n <- nrow(X)
  p <- ncol(X)
  beta_lambda <- solve(t(X) %*% X + lambda * diag(p)) %*% t(X) %*% y
  return(beta_lambda)
}
```

**Part (iv) Calculating $\beta_2$ for $\lambda = 2$**

```R
beta_2 <- ridge_fit(2, data$hp, X)
print(beta_2)
```

**Part (v) Creating a Matrix of $\beta_\lambda$ for Different $\lambda$ Values**

```R
lambda_values <- seq(0, 100, by = 0.1)
matrix_LAMBDA <- matrix(nrow = length(lambda_values), ncol = 4)

for (i in 1:length(lambda_values)) {
  beta_lambda <- ridge_fit(lambda_values[i], data$hp, X)
  matrix_LAMBDA[i, ] <- beta_lambda
}

colnames(matrix_LAMBDA) <- colnames(X)
```

This code will create a matrix where each row corresponds to a different value of $\lambda$ and each column corresponds to the coefficients of the model for that particular $\lambda$.
